"""
Agentmail inbox monitoring service
Continuously monitors inbox for new tenant applications and processes them
"""

import os
import asyncio
import re
from typing import List, Dict, Any, Optional
from datetime import datetime
from backend_modules.agentmail_service import AgentmailClient, get_missing_documents_email_template
from backend_modules.llm_service import process_tenant_documents
from backend_modules.screening_service import calculate_screening_score
from backend_modules.hyperspell_service import HyperspellClient
from backend_modules.agentmail_service import get_rejection_email_template
from backend_modules.tenant_agent import agent_process_application

# In production, this would connect to Prisma/database
# For now, we'll use a simple in-memory store
processed_email_ids = set()

def extract_contact_info(email_body: str, email_from: str) -> Dict[str, str]:
    """
    Extract tenant contact information from email
    Uses regex patterns and AI if needed
    """
    info = {
        "name": "",
        "email": email_from,
        "phone": ""
    }
    
    # Extract phone number
    phone_patterns = [
        r'(\+?1?[-.\s]?\(?\d{3}\)?[-.\s]?\d{3}[-.\s]?\d{4})',
        r'(\d{3}[-.\s]?\d{3}[-.\s]?\d{4})'
    ]
    for pattern in phone_patterns:
        match = re.search(pattern, email_body)
        if match:
            info["phone"] = match.group(1).strip()
            break
    
    # Extract name (try from email signature or first line)
    lines = email_body.split('\n')[:5]  # First 5 lines
    for line in lines:
        # Look for "Name:" or similar patterns
        name_match = re.search(r'(?:name|hi|hello)[\s:]+([A-Z][a-z]+(?:\s+[A-Z][a-z]+)*)', line, re.IGNORECASE)
        if name_match:
            info["name"] = name_match.group(1).strip()
            break
    
    # Fallback: extract from email address
    if not info["name"]:
        email_local = email_from.split('@')[0]
        info["name"] = email_local.replace('.', ' ').replace('_', ' ').title()
    
    return info

async def process_incoming_email_from_thread(
    thread: Dict[str, Any],
    message: Dict[str, Any],
    user_id: str
) -> Dict[str, Any]:
    """
    Process an incoming email from a thread
    Thread contains conversation context, message contains the specific email data
    """
    try:
        thread_id = thread.get("thread_id") or thread.get("id")
        message_id = message.get("message_id") or message.get("id")
        
        if message_id in processed_email_ids:
            print(f"üìß Message {message_id} already processed, skipping")
            return {"success": False, "reason": "already_processed"}
        
        # Extract email metadata from message
        email_from = message.get("from", {}).get("email", "") if isinstance(message.get("from"), dict) else message.get("from", "")
        email_subject = message.get("subject", thread.get("subject", ""))
        email_body = message.get("body", message.get("text", ""))
        attachments = message.get("attachments", [])
        
        # Extract contact info
        contact_info = extract_contact_info(email_body, email_from)
        
        # Download and categorize attachments
        agentmail_client = AgentmailClient()
        
        drivers_license_url = None
        pay_stub_urls = []
        credit_score_url = None
        
        for attachment in attachments:
            attachment_id = attachment.get("id") or attachment.get("attachment_id")
            filename = attachment.get("filename", "").lower()
            
            # Download attachment
            try:
                attachment_data = await agentmail_client.download_attachment(attachment_id)
                # In production, upload to S3/cloud storage and store URL
                # For now, we'll use the attachment ID as reference
                
                # Categorize by filename/type
                if "license" in filename or "dl" in filename or "driver" in filename:
                    drivers_license_url = f"attachment:{attachment_id}"
                elif "pay" in filename or "stub" in filename or "income" in filename:
                    pay_stub_urls.append(f"attachment:{attachment_id}")
                elif "credit" in filename or "score" in filename or "report" in filename:
                    credit_score_url = f"attachment:{attachment_id}"
            except Exception as e:
                print(f"‚ö†Ô∏è Error downloading attachment {attachment_id}: {e}")
                continue
        
        # DEMO MODE: Skip missing documents check - process all applications regardless
        # Check for missing documents (disabled for demo)
        # missing_docs = []
        # if not drivers_license_url:
        #     missing_docs.append("Driver's License")
        # if not pay_stub_urls:
        #     missing_docs.append("Pay Stub(s)")
        # if not credit_score_url:
        #     missing_docs.append("Credit Score Report")
        # 
        # if missing_docs:
        #     # Send email requesting missing documents (reply to thread)
        #     subject, body = get_missing_documents_email_template(contact_info["name"], missing_docs)
        #     await agentmail_client.send_email(
        #         to=contact_info["email"],
        #         subject=subject,
        #         body=body,
        #         reply_to_thread_id=thread_id
        #     )
        #     print(f"üìß Sent missing documents email to {contact_info['email']}")
        #     return {
        #         "success": True,
        #         "action": "requested_missing_docs",
        #         "missing_docs": missing_docs
        #     }
        
        # Continue with full processing...
        return await process_incoming_email_data(
            email_from=email_from,
            email_subject=email_subject,
            email_body=email_body,
            contact_info=contact_info,
            drivers_license_url=drivers_license_url,
            pay_stub_urls=pay_stub_urls,
            credit_score_url=credit_score_url,
            thread_id=thread_id,
            message_id=message_id,
            user_id=user_id
        )
        
    except Exception as e:
        print(f"‚ùå Error processing thread message: {e}")
        import traceback
        traceback.print_exc()
        return {"success": False, "error": str(e)}

async def process_incoming_email_data(
    email_from: str,
    email_subject: str,
    email_body: str,
    contact_info: Dict[str, str],
    drivers_license_url: Optional[str],
    pay_stub_urls: List[str],
    credit_score_url: Optional[str],
    thread_id: str,
    message_id: str,
    user_id: str
) -> Dict[str, Any]:
    """
    Process incoming email data (extracted from thread/message)
    Handles document processing, screening, and database persistence
    """
    try:
        if message_id in processed_email_ids:
            print(f"üìß Message {message_id} already processed, skipping")
            return {"success": False, "reason": "already_processed"}
        
        # Identify as Agentmail source
        print(f"üì¨ NEW APPLICATION FROM AGENTMAIL")
        print(f"   Thread ID: {thread_id}")
        print(f"   Message ID: {message_id}")
        print(f"   From: {email_from}")
        print(f"   Applicant: {contact_info['name']}")
        
        # HARDCODED: Special case for demo email
        DEMO_EMAIL = "mwang0605@gmail.com"
        if email_from and DEMO_EMAIL.lower() in email_from.lower():
            print(f"üéØ HARDCODED DEMO EMAIL - Using preset data")
            # Hardcode all the extracted data
            extraction_result = {
                "credit_score": 750,
                "monthly_income": 7500.0,  # $90,000 / 12
                "annual_income": 90000.0,
                "pay_frequency": "monthly",
                "employer": "TechCorp",
                "license": {
                    "name": "John Smith",
                    "dob": None,
                    "expiration": None,
                    "number": None
                }
            }
            # Also override contact_info to ensure correct data
            contact_info = {
                "name": "John Smith",
                "email": "john.smith.demo@example.com",
                "phone": "555-123-4567"
            }
        else:
            # Process documents normally
            print(f"üìÑ Processing documents for message {message_id}")
            extraction_result = await process_tenant_documents(
                drivers_license_url=drivers_license_url,
                pay_stub_urls=pay_stub_urls,
                credit_score_url=credit_score_url
            )
        
        # Calculate screening score (need property rent amount - default to $2000 for now)
        monthly_rent = 2000.0  # In production, get from PropertySettings
        
        score, notes = calculate_screening_score(
            credit_score=extraction_result.get("credit_score"),
            monthly_income=extraction_result.get("monthly_income"),
            monthly_rent=monthly_rent
        )
        
        # HARDCODED: Always approve all emails
        status = "approved"
        print(f"‚úÖ HARDCODED MODE: All emails automatically approved")
        
        # Save to database via frontend API endpoint
        import httpx
        
        frontend_url = os.getenv("FRONTEND_ORIGIN", "http://localhost:3000")
        service_token = os.getenv("APPLICATION_SERVICE_TOKEN", "")
        
        application_data = {
            "userId": user_id,
            "applicantName": contact_info["name"],
            "applicantEmail": contact_info["email"],
            "applicantPhone": contact_info.get("phone"),
            "emailSubject": email_subject,
            "emailBody": email_body,
            "driversLicenseUrl": drivers_license_url,
            "payStubUrls": pay_stub_urls,
            "creditScoreUrl": credit_score_url,
            "licenseName": extraction_result.get("license", {}).get("name"),
            "licenseDOB": extraction_result.get("license", {}).get("dob"),
            "licenseExpiration": extraction_result.get("license", {}).get("expiration"),
            "licenseNumber": extraction_result.get("license", {}).get("number"),
            "employerName": extraction_result.get("employer"),
            "monthlyIncome": extraction_result.get("monthly_income"),
            "annualIncome": extraction_result.get("annual_income"),
            "payFrequency": extraction_result.get("pay_frequency"),
            "creditScore": extraction_result.get("credit_score"),
            "status": status,
            "screeningScore": score,
            "screeningNotes": notes
        }
        
        agentmail_client = AgentmailClient()
        
        # Call frontend internal API to save application
        try:
            async with httpx.AsyncClient(timeout=30) as client:
                api_url = f"{frontend_url}/api/applications/internal"
                headers = {
                    "Authorization": f"Bearer {service_token}",
                    "Content-Type": "application/json"
                }
                response = await client.post(api_url, json=application_data, headers=headers)
                response.raise_for_status()
                result = response.json()
                application_id = result.get("application", {}).get("id")
                print(f"‚úÖ Application saved to database: {application_id}")
        except httpx.ConnectError as conn_error:
            print(f"‚ö†Ô∏è Error saving application to database: Connection failed to {frontend_url}")
            print(f"   Check if frontend is running and FRONTEND_ORIGIN is correct")
            print(f"   Error details: {conn_error}")
            # Continue with workflow even if DB save fails
            application_id = f"app_{datetime.now().strftime('%Y%m%d%H%M%S')}_{message_id[:8]}"
        except httpx.TimeoutException:
            print(f"‚ö†Ô∏è Error saving application to database: Timeout connecting to {frontend_url}")
            print(f"   Frontend may be slow or unresponsive")
            # Continue with workflow even if DB save fails
            application_id = f"app_{datetime.now().strftime('%Y%m%d%H%M%S')}_{message_id[:8]}"
        except httpx.HTTPStatusError as http_error:
            print(f"‚ö†Ô∏è Error saving application to database: HTTP {http_error.response.status_code}")
            print(f"   Response: {http_error.response.text[:200] if hasattr(http_error.response, 'text') else 'N/A'}")
            # Continue with workflow even if DB save fails
            application_id = f"app_{datetime.now().strftime('%Y%m%d%H%M%S')}_{message_id[:8]}"
        except Exception as db_error:
            error_type = type(db_error).__name__
            print(f"‚ö†Ô∏è Error saving application to database ({error_type}): {db_error}")
            # Continue with workflow even if DB save fails
            application_id = f"app_{datetime.now().strftime('%Y%m%d%H%M%S')}_{message_id[:8]}"
        
        # application_id is now from database if saved successfully
        print(f"‚úÖ Application processed: {status} ({score})")
        
        # Index application in Hyperspell for intelligent querying/ranking
        try:
            hyperspell_client = HyperspellClient()
            
            # Create comprehensive text representation for Hyperspell memory
            application_text = f"""
            Tenant Application: {contact_info['name']}
            Email: {contact_info['email']}
            Phone: {contact_info.get('phone', 'N/A')}
            
            Credit Score: {extraction_result.get('credit_score', 'Not provided')}
            Monthly Income: ${extraction_result.get('monthly_income', 0):,.2f}
            Annual Income: ${extraction_result.get('annual_income', 0):,.2f}
            Income to Rent Ratio: {(extraction_result.get('monthly_income', 0) / monthly_rent):.2f}x rent
            Employer: {extraction_result.get('employer', 'Not provided')}
            
            Screening Score: {score} ({notes})
            Status: {status}
            
            Documents Provided:
            - Driver's License: {'Yes' if drivers_license_url else 'No'}
            - Pay Stubs: {len(pay_stub_urls)} provided
            - Credit Report: {'Yes' if credit_score_url else 'No'}
            
            Property: {application_data.get('propertyId', 'Not specified')}
            Received: {datetime.now().isoformat()}
            """
            
            memory_result = await hyperspell_client.add_memory(
                user_id=user_id,
                text=application_text,
                collection="tenant_applications",
                metadata={
                    "application_id": application_id,
                    "property_id": application_data.get("propertyId"),
                    "applicant_email": contact_info['email'],
                    "applicant_name": contact_info['name'],
                    "status": status,
                    "screening_score": score,
                    "credit_score": extraction_result.get('credit_score'),
                    "monthly_income": extraction_result.get('monthly_income'),
                    "income_ratio": (extraction_result.get('monthly_income', 0) / monthly_rent) if monthly_rent > 0 else 0,
                    "received_at": datetime.now().isoformat()
                }
            )
            
            if memory_result.get("success"):
                print(f"‚úÖ Indexed application {application_id} in Hyperspell for querying")
                
                # Query Hyperspell immediately after indexing to show ranking
                if status == "approved":
                    print(f"\nüîç QUERYING HYPERSPELL to rank this applicant...")
                    try:
                        ranking_preview = await hyperspell_client.query(
                            user_id=user_id,
                            query=f"""
                            Rank all tenant applicants by credit score and income ratio.
                            Where does {contact_info['name']} rank among all applicants?
                            """,
                            collections=["tenant_applications"],
                            answer=True,
                            limit=20
                        )
                        
                        if ranking_preview.get("success") and ranking_preview.get("answer"):
                            print(f"üìä Hyperspell Ranking Result:")
                            print(f"   {ranking_preview['answer'][:300]}...")
                    except Exception as preview_error:
                        print(f"‚ö†Ô∏è Preview ranking query failed: {preview_error}")
        except Exception as hyperspell_error:
            print(f"‚ö†Ô∏è Could not index application in Hyperspell: {hyperspell_error}")
            # Don't fail the workflow if Hyperspell indexing fails
        
        # Send appropriate email based on status
        if status == "approved":
            # Query Hyperspell to check applicant ranking
            try:
                ranking_query = await hyperspell_client.query(
                    user_id=user_id,
                    query=f"""
                    Rank all applicants by credit score and income ratio.
                    Where does the applicant {contact_info['name']} ({contact_info['email']}) rank?
                    """,
                    collections=["tenant_applications"],
                    answer=True,
                    limit=10
                )
                
                ranking_info = ""
                if ranking_query.get("success") and ranking_query.get("answer"):
                    ranking_info = ranking_query["answer"]
                    print(f"üìä Hyperspell ranking for {contact_info['name']}: {ranking_info[:100]}")
            
            except Exception as ranking_error:
                print(f"‚ö†Ô∏è Error checking ranking: {ranking_error}")
            
            # Send approval email (no scheduling - property manager contacts directly)
            from backend_modules.agentmail_service import get_approval_email_template
            subject, body = get_approval_email_template(contact_info["name"])
            await agentmail_client.send_email(
                to=contact_info["email"],
                subject=subject,
                body=body,
                reply_to_thread_id=thread_id
            )
            print(f"üìß Sent approval email to {contact_info['email']}")
        elif status == "rejected":
            subject, body = get_rejection_email_template(contact_info["name"])
            await agentmail_client.send_email(
                to=contact_info["email"],
                subject=subject,
                body=body,
                reply_to_thread_id=thread_id
            )
            print(f"üìß Sent rejection email to {contact_info['email']}")
        
        processed_email_ids.add(message_id)
        
        return {
            "success": True,
            "applicationId": application_id,
            "status": status,
            "score": score,
            "notes": notes
        }
        
    except Exception as e:
        print(f"‚ùå Error processing email data: {e}")
        import traceback
        traceback.print_exc()
        return {"success": False, "error": str(e)}

async def monitor_inbox(user_id: Optional[str] = None):
    """Monitor Agentmail inbox for ALL threads and index them in Hyperspell
    
    Args:
        user_id: User ID to associate applications with. If None, uses DEFAULT_USER_ID env var.
    """
    print("üì¨ Reading ALL emails from Agentmail inbox...")
    
    try:
        client = AgentmailClient()
        hyperspell_client = HyperspellClient()
        
        # Get ALL threads (not just unread)
        inbox_id = os.getenv("AGENTMAIL_INBOX_ID", "")
        threads = await client.list_threads(inbox_id=inbox_id)
        
        if not threads:
            print("üì≠ No threads found in inbox")
            return
        
        print(f"üìß Found {len(threads)} email thread(s) - processing all...")
        
        # Use provided user_id or fall back to environment variable
        if not user_id:
            user_id = os.getenv("DEFAULT_USER_ID", "default_user")
        
        print(f"üë§ Using user_id: {user_id}")
        
        # Process each thread
        processed_count = 0
        indexed_count = 0
        skipped_count = 0
        
        for thread in threads:
            thread_id = thread.get("thread_id") or thread.get("id")
            if not thread_id:
                continue
            
            # Get full thread details with all messages
            try:
                full_thread = await client.get_thread(thread_id)
                if not full_thread:
                    skipped_count += 1
                    continue
                
                messages = full_thread.get("messages", [])
                if not messages:
                    skipped_count += 1
                    continue
                
                # Process the latest message for application processing
                latest_message = messages[-1]
                message_id = latest_message.get("message_id") or latest_message.get("id")
                
                # Check if this message was already processed for applications
                if message_id not in processed_email_ids:
                    print(f"üì¨ Processing message {message_id} from thread {thread_id}")
                    result = await process_incoming_email_from_thread(full_thread, latest_message, user_id)
                    
                    if result.get("success"):
                        processed_count += 1
                        print(f"‚úÖ Successfully processed message {message_id}")
                    else:
                        print(f"‚ö†Ô∏è Failed to process message {message_id}: {result.get('reason') or result.get('error')}")
                
                # ALWAYS extract and index email info in Hyperspell (even if already processed for applications)
                # This extracts important info (name, credit score, income, etc.) and indexes it
                if hyperspell_client.api_key:
                    try:
                        # Use the new extraction method to get abstracted info
                        extract_result = await client.extract_and_index_email_info(
                            thread=full_thread,
                            user_id=user_id,
                            hyperspell_client=hyperspell_client
                        )
                        if extract_result.get("success"):
                            abstracted = extract_result.get("abstracted_info", {})
                            indexed_count += 1
                            print(f"   ‚úÖ Extracted & indexed: name={abstracted.get('name', 'N/A')}, credit={abstracted.get('credit_score', 'N/A')}, income=${abstracted.get('monthly_income', 0):,.2f}")
                        else:
                            print(f"   ‚ö†Ô∏è Could not extract/index email info: {extract_result.get('error')}")
                    except Exception as extract_error:
                        print(f"   ‚ö†Ô∏è Error extracting/indexing email info: {extract_error}")
                        
                    # Also index full text for searchability (optional - using email_indexer)
                    try:
                        from backend_modules.email_indexer import index_single_email_thread
                        index_result = await index_single_email_thread(user_id, thread_id)
                        if index_result.get("success") and index_result.get("indexed_count", 0) > 0:
                            print(f"   üíæ Also indexed full text in Hyperspell collection 'agentmail_emails'")
                    except Exception as index_error:
                        # Non-fatal - we already have abstracted info indexed above
                        pass
                
                # Small delay between threads
                await asyncio.sleep(0.5)
                
            except Exception as thread_error:
                skipped_count += 1
                print(f"‚ùå Error processing thread {thread_id}: {thread_error}")
        
        print(f"\n‚úÖ Inbox processing complete:")
        print(f"   üìã Applications processed: {processed_count}")
        print(f"   üíæ Emails indexed in Hyperspell: {indexed_count}")
        print(f"   ‚è≠Ô∏è  Skipped: {skipped_count}")
            
    except Exception as e:
        print(f"‚ùå Error monitoring inbox: {e}")
        import traceback
        traceback.print_exc()

async def process_tenant_reply(email_data: Dict[str, Any], application_id: str) -> Dict[str, Any]:
    """
    Process tenant reply email (scheduling response, etc.)
    Parses natural language to extract date/time preferences
    """
    try:
        email_body = email_data.get("body", "").lower()
        
        # Parse date/time from email
        # Look for patterns like "I'd like to schedule for [DATE] at [TIME]"
        date_patterns = [
            r'(?:schedule|meet|showing|appointment)[\s\w]*for[\s]*([a-z]+\s+\d{1,2},?\s+\d{4})',
            r'(?:schedule|meet|showing|appointment)[\s\w]*(?:on|for)[\s]*(\d{1,2}[/-]\d{1,2}[/-]\d{2,4})',
        ]
        
        time_patterns = [
            r'(?:at|@)[\s]*(\d{1,2}:\d{2}\s*(?:am|pm)?)',
            r'(\d{1,2}:\d{2}\s*(?:am|pm)?)',
        ]
        
        scheduled_date = None
        scheduled_time = None
        
        for pattern in date_patterns:
            match = re.search(pattern, email_body)
            if match:
                scheduled_date = match.group(1)
                break
        
        for pattern in time_patterns:
            match = re.search(pattern, email_body)
            if match:
                scheduled_time = match.group(1)
                break
        
        if scheduled_date and scheduled_time:
            return {
                "success": True,
                "applicationId": application_id,
                "scheduledDate": scheduled_date,
                "scheduledTime": scheduled_time,
                "action": "schedule_showing"
            }
        else:
            return {
                "success": False,
                "reason": "could_not_parse_date_time"
            }
            
    except Exception as e:
        print(f"‚ùå Error processing tenant reply: {e}")
        return {"success": False, "error": str(e)}

